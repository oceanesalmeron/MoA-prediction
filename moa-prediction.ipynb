{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Set up"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Make numpy values easier to read.\nnp.set_printoptions(precision=3, suppress=True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/lish-moa/test_features.csv\n/kaggle/input/lish-moa/train_drug.csv\n/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/train_targets_scored.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n/kaggle/input/lish-moa/sample_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Import tensorflow"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import feature_column\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.layers.experimental import preprocessing\n#from tensorboard.plugins.hparams import api as hp","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install -q git+https://github.com/tensorflow/docs\n\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\nimport tensorflow_docs.plots\nfrom matplotlib import pyplot as plt","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3 is available.\r\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nimport tempfile","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data reading"},{"metadata":{},"cell_type":"markdown","source":"### 1. Use Pandas to create a dataframe"},{"metadata":{},"cell_type":"markdown","source":"#### Setting our batch size"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create dataframe for features and targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\", nrows=20)\ntargets = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\", nrows=20)\ntest = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\", nrows=20)\n\ncols_features = features.columns\ncols_targets = targets.columns\n\nnum_features = len(cols_features)\nnum_targets = len(cols_targets)\n\nprint(\"Number of features:\" , num_features)\nprint(\"Number of targets:\" , num_targets)","execution_count":6,"outputs":[{"output_type":"stream","text":"Number of features: 876\nNumber of targets: 207\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gcols = [g for g in features.columns if \"g-\" in g]\nccols = [c for c in features.columns if \"c-\" in c]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":129,"outputs":[{"output_type":"execute_result","execution_count":129,"data":{"text/plain":"         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n\n      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n\n     c-96    c-97    c-98    c-99  \n0 -0.3981  0.2139  0.3801  0.4176  \n1  0.1522  0.1241  0.6077  0.7371  \n2 -0.6417 -0.2187 -1.4080  0.6931  \n3 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.1094  0.2885 -0.3786  0.7125  \n\n[5 rows x 876 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>cp_type</th>\n      <th>cp_time</th>\n      <th>cp_dose</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>...</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_000644bb2</td>\n      <td>trt_cp</td>\n      <td>24</td>\n      <td>D1</td>\n      <td>1.0620</td>\n      <td>0.5577</td>\n      <td>-0.2479</td>\n      <td>-0.6208</td>\n      <td>-0.1944</td>\n      <td>-1.0120</td>\n      <td>...</td>\n      <td>0.2862</td>\n      <td>0.2584</td>\n      <td>0.8076</td>\n      <td>0.5523</td>\n      <td>-0.1912</td>\n      <td>0.6584</td>\n      <td>-0.3981</td>\n      <td>0.2139</td>\n      <td>0.3801</td>\n      <td>0.4176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_000779bfc</td>\n      <td>trt_cp</td>\n      <td>72</td>\n      <td>D1</td>\n      <td>0.0743</td>\n      <td>0.4087</td>\n      <td>0.2991</td>\n      <td>0.0604</td>\n      <td>1.0190</td>\n      <td>0.5207</td>\n      <td>...</td>\n      <td>-0.4265</td>\n      <td>0.7543</td>\n      <td>0.4708</td>\n      <td>0.0230</td>\n      <td>0.2957</td>\n      <td>0.4899</td>\n      <td>0.1522</td>\n      <td>0.1241</td>\n      <td>0.6077</td>\n      <td>0.7371</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_000a6266a</td>\n      <td>trt_cp</td>\n      <td>48</td>\n      <td>D1</td>\n      <td>0.6280</td>\n      <td>0.5817</td>\n      <td>1.5540</td>\n      <td>-0.0764</td>\n      <td>-0.0323</td>\n      <td>1.2390</td>\n      <td>...</td>\n      <td>-0.7250</td>\n      <td>-0.6297</td>\n      <td>0.6103</td>\n      <td>0.0223</td>\n      <td>-1.3240</td>\n      <td>-0.3174</td>\n      <td>-0.6417</td>\n      <td>-0.2187</td>\n      <td>-1.4080</td>\n      <td>0.6931</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_0015fd391</td>\n      <td>trt_cp</td>\n      <td>48</td>\n      <td>D1</td>\n      <td>-0.5138</td>\n      <td>-0.2491</td>\n      <td>-0.2656</td>\n      <td>0.5288</td>\n      <td>4.0620</td>\n      <td>-0.8095</td>\n      <td>...</td>\n      <td>-2.0990</td>\n      <td>-0.6441</td>\n      <td>-5.6300</td>\n      <td>-1.3780</td>\n      <td>-0.8632</td>\n      <td>-1.2880</td>\n      <td>-1.6210</td>\n      <td>-0.8784</td>\n      <td>-0.3876</td>\n      <td>-0.8154</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_001626bd3</td>\n      <td>trt_cp</td>\n      <td>72</td>\n      <td>D2</td>\n      <td>-0.3254</td>\n      <td>-0.4009</td>\n      <td>0.9700</td>\n      <td>0.6919</td>\n      <td>1.4180</td>\n      <td>-0.8244</td>\n      <td>...</td>\n      <td>0.0042</td>\n      <td>0.0048</td>\n      <td>0.6670</td>\n      <td>1.0690</td>\n      <td>0.5523</td>\n      <td>-0.3031</td>\n      <td>0.1094</td>\n      <td>0.2885</td>\n      <td>-0.3786</td>\n      <td>0.7125</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 876 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets.head()","execution_count":130,"outputs":[{"output_type":"execute_result","execution_count":130,"data":{"text/plain":"         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n0  id_000644bb2                            0                       0   \n1  id_000779bfc                            0                       0   \n2  id_000a6266a                            0                       0   \n3  id_0015fd391                            0                       0   \n4  id_001626bd3                            0                       0   \n\n   acat_inhibitor  acetylcholine_receptor_agonist  \\\n0               0                               0   \n1               0                               0   \n2               0                               0   \n3               0                               0   \n4               0                               0   \n\n   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n0                                  0                               0   \n1                                  0                               0   \n2                                  0                               0   \n3                                  0                               0   \n4                                  0                               0   \n\n   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n0                           0                              0   \n1                           0                              0   \n2                           0                              0   \n3                           0                              0   \n4                           0                              0   \n\n   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                           0  ...                                      0   \n1                           0  ...                                      0   \n2                           0  ...                                      0   \n3                           0  ...                                      0   \n4                           0  ...                                      0   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0             0                0                  0   \n1             0                0                  0   \n2             0                0                  0   \n3             0                0                  0   \n4             0                0                  0   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                          0                                      0   \n1                          0                                      0   \n2                          0                                      0   \n3                          0                                      0   \n4                          0                                      0   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0                0          0                           0              0  \n1                0          0                           0              0  \n2                0          0                           0              0  \n3                0          0                           0              0  \n4                0          0                           0              0  \n\n[5 rows x 207 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>...</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_000644bb2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_000779bfc</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_000a6266a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_0015fd391</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_001626bd3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 207 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2. Building data pipelins"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_types = [str(), str(), str(), str()] + [float()]*(num_features-4)\ntargets_types = [str()] + [float()]*(num_targets-1)\n\nfeatures = tf.data.experimental.CsvDataset(\"/kaggle/input/lish-moa/train_features.csv\",\n                                           record_defaults=features_types,\n                                           #select_cols\n                                           header=True)\n\ntargets = tf.data.experimental.CsvDataset(\"/kaggle/input/lish-moa/train_targets_scored.csv\",\n                                          record_defaults=targets_types,\n                                          header=True)\n\ntest = tf.data.experimental.CsvDataset(\"/kaggle/input/lish-moa/test_features.csv\",\n                                           record_defaults=features_types,\n                                           #select_cols=(gcols + ccols),\n                                           header=True)\n\ndataset = tf.data.Dataset.zip((features, targets))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split dataset into train and val\ndataset_size = dataset.reduce(0, lambda x, _: x + 1).numpy()\n\ntrain_size = int(0.7*dataset_size)\nval_size = dataset_size - train_size\n\ntrain = dataset.take(train_size)\nval = dataset.skip(train_size)\nval = dataset.take(val_size)\n\ntrain_size = train.reduce(0, lambda x, _: x + 1).numpy()\nval_size = val.reduce(0, lambda x, _: x + 1).numpy()\n\nprint(\"Full dataset size:\", dataset_size)\nprint(\"Train dataset size:\", train_size)\nprint(\"Val dataset size:\", val_size)","execution_count":9,"outputs":[{"output_type":"stream","text":"Full dataset size: 23814\nTrain dataset size: 16669\nVal dataset size: 7145\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _preprocess_line(features, targets):\n    # Pack the result into a dictionary\n    features = dict(zip(cols_features, features))\n    features.pop('sig_id')\n\n    targets = tf.stack(targets[1:])\n    \n    return features, targets\n\ntrain = train.map(_preprocess_line)\ntrain = train.batch(BATCH_SIZE)\n\nval = val.map(_preprocess_line)\nval = val.batch(BATCH_SIZE)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature_batch, label_batch in train.take(1):\n    print('First 5 features:', list(feature_batch.keys())[:5])\n    print('A batch of cp_types:', feature_batch['cp_type'].numpy())\n    print('A batch of cp_times:', feature_batch['cp_time'].numpy())\n    print('A batch of targets:', label_batch.numpy() )","execution_count":11,"outputs":[{"output_type":"stream","text":"First 5 features: ['cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1']\nA batch of cp_types: [b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp'\n b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp'\n b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp'\n b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'ctl_vehicle' b'trt_cp'\n b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp']\nA batch of cp_times: [b'24' b'72' b'48' b'48' b'72' b'24' b'24' b'48' b'48' b'48' b'72' b'48'\n b'48' b'48' b'72' b'48' b'48' b'24' b'72' b'48' b'48' b'48' b'72' b'72'\n b'72' b'48' b'72' b'48' b'48' b'72' b'72' b'48']\nA batch of targets: [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### 1. Normalization of numerical columns"},{"metadata":{},"cell_type":"markdown","source":"Prepare encoded features array"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = []","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in (gcols + ccols):\n    feature_columns.append(feature_column.numeric_column(name))","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Encoding of categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_time_type = feature_column.categorical_column_with_vocabulary_list(\n      'cp_time', ['24', '48', '72'])\ncp_type_type = feature_column.categorical_column_with_vocabulary_list(\n      'cp_type', ['trt_cp', 'ctl_vehicle'])\ncp_dose_type = feature_column.categorical_column_with_vocabulary_list(\n      'cp_dose', ['D1', 'D2'])\n\ncp_time_type_one_hot = feature_column.indicator_column(cp_time_type)\ncp_type_type_one_hot = feature_column.indicator_column(cp_type_type)\ncp_dose_type_one_hot = feature_column.indicator_column(cp_dose_type)\n\nfeature_columns.append(cp_time_type_one_hot)\nfeature_columns.append(cp_type_type_one_hot)\nfeature_columns.append(cp_dose_type_one_hot)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_layer = tf.keras.layers.DenseFeatures(feature_columns)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  feature_layer,\n  layers.Dense(128, activation='relu'),\n  layers.Dense(128, activation='relu'),\n  layers.Dropout(.1),\n  layers.Dense(206)\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train,\n          validation_data=val,\n          epochs=10)","execution_count":145,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n    104/Unknown - 7s 67ms/step - loss: 0.1197 - accuracy: 0.0183","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-145-a4cf7d3c1c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=10)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3180\u001b[0m           \" hashable.  Original error: %s\" % e)\n\u001b[1;32m   3181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3182\u001b[0;31m     \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     return (type(other) is type(self) and\n\u001b[0;32m--> 296\u001b[0;31m             self.__get_cmp_key() == other.__get_cmp_key())\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    352\u001b[0m           tuple([self.__make_cmp_key(key),\n\u001b[1;32m    353\u001b[0m                  self.__make_cmp_key(value[key])])\n\u001b[0;32m--> 354\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m           tuple([self.__make_cmp_key(key),\n\u001b[1;32m    353\u001b[0m                  self.__make_cmp_key(value[key])])\n\u001b[0;32m--> 354\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(val)\nprint(\"Accuracy\", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"regularizer_histories = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_and_fit(model, name, optimizer=None, max_epochs=10000):\n    if optimizer is None:\n        optimizer = get_optimizer()\n    model.compile(optimizer=optimizer,loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n                  metrics=[tf.keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'),\n                           'accuracy'])\n\n    model.summary()\n\n    history = model.fit(\n        train_ds,\n        steps_per_epoch = STEPS_PER_EPOCH,\n        epochs=max_epochs,\n        validation_data=validate_ds,\n        callbacks=get_callbacks(name),\n        verbose=0)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_callbacks(name):\n    return [\n        tfdocs.modeling.EpochDots(),\n        tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n        tf.keras.callbacks.TensorBoard(logdir/name),\n    ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. L2 Regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"l2_model = tf.keras.Sequential([\n  feature_layer,\n  layers.Dense(128, activation='relu',\n               kernel_regularizer=regularizers.l2(0.00001),\n               input_shape=(num_features,)),\n  layers.Dense(128, activation='relu', \n               kernel_regularizer=regularizers.l2(0.00001)),\n  layers.Dense(206)\n])\n\n\nl2_model.compile(optimizer='adam', \n                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                 metrics=[tf.keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'),'accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regularizer_histories['l2'] = l2_model.fit(train,\n                                           validation_data=val,\n                                           callbacks=get_callbacks('l2'),\n                                           epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotter = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=10)\nplt.figure(figsize=(10, 6))\nplotter.plot(regularizer_histories)\nplt.ylim([0.01, 0.4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Drop out regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"dp_model = tf.keras.Sequential([   \n    feature_layer,\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(.1),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(.1),\n    layers.Dense(206)\n])\n\ndp_model.compile(optimizer='adam', \n                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'), \n                 metrics=[tf.keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'),'accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regularizer_histories['dp'] = dp_model.fit(train,\n                                           validation_data=val,\n                                           callbacks=get_callbacks('dp'),\n                                           epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplotter.plot(regularizer_histories)\nplt.ylim([0.01, 0.7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Batch Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_model = tf.keras.Sequential([\n    feature_layer,\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(206)\n])\n\nbatch_model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regularizer_histories['batch'] = batch_model.fit(train,\n                                           validation_data=val,\n                                           callbacks=get_callbacks('bacth'),\n                                           epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplotter.plot(regularizer_histories)\nplt.ylim([0.01, 0.7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Weight initialization"},{"metadata":{},"cell_type":"markdown","source":"### 5. Combination"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_model = tf.keras.Sequential([\n    feature_layer,\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(128, activation='relu'), \n    layers.Dropout(.1),\n    layers.Dense(206)\n])\n\nall_model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nregularizer_histories['all'] = all_model.fit(train,\n                                           validation_data=val,\n                                           callbacks=get_callbacks('all'),\n                                           epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplotter.plot(regularizer_histories)\nplt.ylim([0.01, 0.7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Variance & Bias Analysis"},{"metadata":{},"cell_type":"markdown","source":"### 1. Plot the training and validation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=10)\nplt.figure(figsize=(10, 6))\nplot_loss.plot(regularizer_histories)\nplt.ylim([0.01, 0.2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Learning curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning with Keras Tuner"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q -U keras-tuner\nimport kerastuner as kt\nimport IPython","execution_count":154,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3 is available.\r\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_builder(hp):\n    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n\n    hp_model = tf.keras.Sequential([\n        feature_layer,\n        layers.Dense(units = hp_units, activation='relu'),\n        layers.Dense(206)\n    ])\n\n    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n\n    hp_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n                    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), \n                    metrics = ['accuracy'])\n    return hp_model","execution_count":161,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuner = kt.Hyperband(model_builder,\n                     objective = 'val_accuracy', \n                     max_epochs = 10,\n                     factor = 3,\n                     directory = 'my_dir',\n                     project_name = 'intro_to_kt')  ","execution_count":165,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"__init__() got an unexpected keyword argument 'max_trials'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-165-2528c9826b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'my_dir'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                      project_name = 'intro_to_kt')  \n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kerastuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                  **kwargs):\n\u001b[1;32m     58\u001b[0m         super(MultiExecutionTuner, self).__init__(\n\u001b[0;32m---> 59\u001b[0;31m             oracle, hypermodel, **kwargs)\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             raise ValueError(\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_trials'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClearTrainingOutput(tf.keras.callbacks.Callback):\n    def on_train_end(*args, **kwargs):\n        IPython.display.clear_output(wait = True)","execution_count":159,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuner.search(train, epochs = 2, validation_data = (val), callbacks = [ClearTrainingOutput()])\n\n# Get the optimal hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n\nprint(f\"\"\"\nThe hyperparameter search is complete. The optimal number of units in the first densely-connected\nlayer is {best_hps.get('units')} and the optimal learning rate for the optimizer\nis {best_hps.get('learning_rate')}.\n\"\"\")","execution_count":176,"outputs":[{"output_type":"stream","text":"Trial 10 Complete [00h 04m 39s]\nval_accuracy: 0.17872637510299683\n\nBest val_accuracy So Far: 0.33463960886001587\nTotal elapsed time: 00h 34m 00s\n\nThe hyperparameter search is complete. The optimal number of units in the first densely-connected\nlayer is 480 and the optimal learning rate for the optimizer\nis 0.001.\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"hp_model = tuner.hypermodel.build(best_hps)\nhp_model.fit(train, epochs = 10, validation_data = val)","execution_count":177,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n521/521 [==============================] - 56s 108ms/step - loss: 0.0294 - accuracy: 0.0933 - val_loss: 0.0157 - val_accuracy: 0.1668\nEpoch 2/10\n521/521 [==============================] - 47s 91ms/step - loss: 0.0145 - accuracy: 0.1747 - val_loss: 0.0118 - val_accuracy: 0.2336\nEpoch 3/10\n521/521 [==============================] - 48s 92ms/step - loss: 0.0112 - accuracy: 0.2592 - val_loss: 0.0095 - val_accuracy: 0.3330\nEpoch 4/10\n521/521 [==============================] - 51s 97ms/step - loss: 0.0082 - accuracy: 0.3624 - val_loss: 0.0065 - val_accuracy: 0.4164\nEpoch 5/10\n521/521 [==============================] - 53s 102ms/step - loss: 0.0057 - accuracy: 0.4499 - val_loss: 0.0045 - val_accuracy: 0.4778\nEpoch 6/10\n521/521 [==============================] - 48s 92ms/step - loss: 0.0035 - accuracy: 0.5167 - val_loss: 0.0032 - val_accuracy: 0.5125\nEpoch 7/10\n521/521 [==============================] - 48s 92ms/step - loss: 0.0023 - accuracy: 0.5474 - val_loss: 0.0023 - val_accuracy: 0.5265\nEpoch 8/10\n521/521 [==============================] - 49s 95ms/step - loss: 0.0017 - accuracy: 0.5549 - val_loss: 0.0023 - val_accuracy: 0.5286\nEpoch 9/10\n521/521 [==============================] - 50s 96ms/step - loss: 0.0013 - accuracy: 0.5522 - val_loss: 0.0014 - val_accuracy: 0.5341\nEpoch 10/10\n521/521 [==============================] - 51s 98ms/step - loss: 8.4145e-04 - accuracy: 0.5531 - val_loss: 0.0010 - val_accuracy: 0.5383\n","name":"stdout"},{"output_type":"execute_result","execution_count":177,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7fbf874690>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}